{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:04.569784Z",
     "start_time": "2025-04-07T08:29:52.971792Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from config import get_default_cfg\n",
    "from pruebas import feature_descriptions\n",
    "from sae import VanillaSAE, TopKSAE, BatchTopKSAE, JumpReLUSAE\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer, HookedEncoder\n",
    "from transformers import GPT2Tokenizer, GPT2Model, BertModel, BertTokenizer\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:10.857789Z",
     "start_time": "2025-04-07T08:30:04.584887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sbert = SentenceTransformer('sentence-transformers/paraphrase-mpnet-base-v2')\n",
    "cfg = get_default_cfg()\n",
    "cfg[\"dataset_path\"] = \"ccdv/pubmed-summarization\"\n",
    "\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('ybiku-unir/SBERT-PubMed/sentence-transformers_paraphrase-mpnet-base-v2_blocks.0.hook_embed_3072_topk_32_0.0001_77:v0', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "config_path = os.path.join(artifact_dir, 'config.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "if \"dtype\" in config and isinstance(config[\"dtype\"], str):\n",
    "    if config[\"dtype\"] == \"torch.float32\":\n",
    "        config[\"dtype\"] = torch.float32\n",
    "    elif config[\"dtype\"] == \"torch.float16\":\n",
    "        config[\"dtype\"] = torch.float16\n",
    "\n",
    "sae = TopKSAE(config).to(config[\"device\"])\n",
    "sae.load_state_dict(torch.load(os.path.join(artifact_dir, 'sae.pt')))\n",
    "sae.eval()"
   ],
   "id": "a2c7f905864ee1ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ybiku (ybiku-unir) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>D:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\wandb\\run-20250407_103008-fzbkmsmt</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ybiku-unir/uncategorized/runs/fzbkmsmt' target=\"_blank\">unique-forest-30</a></strong> to <a href='https://wandb.ai/ybiku-unir/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ybiku-unir/uncategorized' target=\"_blank\">https://wandb.ai/ybiku-unir/uncategorized</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ybiku-unir/uncategorized/runs/fzbkmsmt' target=\"_blank\">https://wandb.ai/ybiku-unir/uncategorized/runs/fzbkmsmt</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   2 of 2 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TopKSAE()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### COLLECT THE TOP ACTIVATING EXAMPLES FOR EACH FEATURE"
   ],
   "id": "d8bcc2a73288c66b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:15.531672Z",
     "start_time": "2025-04-07T08:30:11.261505Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(cfg[\"dataset_path\"], \"document\", streaming=True, split=\"train\")",
   "id": "fdb3f803ce3d33e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T11:39:29.195583Z",
     "start_time": "2025-04-06T11:16:34.835531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_examples = int(1e4)\n",
    "num_features = int(3072)\n",
    "top_activations = [[] for _ in range(num_features)]\n",
    "\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= num_examples: break\n",
    "    text = example[\"abstract\"]\n",
    "    embedding = sbert.encode(text, convert_to_tensor=True).squeeze(0).to(cfg[\"device\"])\n",
    "    feature_acts = sae(embedding)['feature_acts']\n",
    "\n",
    "    for j in range(num_features):\n",
    "        activation_value = feature_acts[j].item()\n",
    "        heap = top_activations[j]\n",
    "        if len(heap) < 10:\n",
    "            heapq.heappush(heap, (activation_value, text))\n",
    "        else:\n",
    "            heapq.heappushpop(heap, (activation_value, text))\n",
    "\n",
    "\n",
    "top_activations = [sorted(heap, key=lambda x: x[0], reverse=True) for heap in top_activations]\n",
    "with open(\"top_activations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(top_activations, f, indent=2, ensure_ascii=False)"
   ],
   "id": "12b4189d18a93dd6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### PROMPT ENGINEERING"
   ],
   "id": "b9efb3647120394c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:15.810333Z",
     "start_time": "2025-04-07T08:30:15.548682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_features = int(3072)\n",
    "top_activations = [[] for _ in range(num_features)]\n",
    "\n",
    "with open(\"top_activations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    top_activations = json.load(f)"
   ],
   "id": "ed683c0b354fbd57",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:18.981156Z",
     "start_time": "2025-04-07T08:30:15.827052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_SCAN = 1000\n",
    "INACTIVE_THRESHOLD = 0.02\n",
    "NUM_NEG = 5\n",
    "NUM_POS = 5\n",
    "NUM_FEATURES = 3072\n",
    "\n",
    "with open(\"top_activations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    top_activations = json.load(f)\n",
    "\n",
    "negative_examples = [[] for _ in range(NUM_FEATURES)]\n",
    "for i, example in enumerate(tqdm(dataset)):\n",
    "    if i >= MAX_SCAN: break\n",
    "    text = example[\"abstract\"]\n",
    "    embedding = sbert.encode(text, convert_to_tensor=True).squeeze(0).to(cfg[\"device\"])\n",
    "    feature_acts = sae(embedding)['feature_acts']\n",
    "\n",
    "    for j in range(NUM_FEATURES):\n",
    "        act = feature_acts[j].item()\n",
    "        if act < INACTIVE_THRESHOLD and len(negative_examples[j]) < NUM_NEG:\n",
    "            negative_examples[j].append((act, text))\n",
    "\n",
    "    if all(len(lst) >= NUM_NEG for lst in negative_examples):\n",
    "        break"
   ],
   "id": "df02f34840daa15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  2.00it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:19.090081Z",
     "start_time": "2025-04-07T08:30:19.075906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROMPT_TEMPLATE = \"\"\"You are a meticulous {type} researcher conducting an important investigation into a certain\n",
    "neuron in a language model trained on {subject} papers. Your task is to figure out what\n",
    "sort of behaviour this neuron is responsible for – namely, on what general concepts, features,\n",
    "themes, methodologies or topics does this neuron fire? Here’s how you’ll complete the task:\n",
    "INPUT DESCRIPTION: You will be given two inputs: 1) Max Activating Examples and 2)\n",
    "Zero Activating Examples.\n",
    "1. You will be given several examples of text that activate the neuron, along with a\n",
    "number being how much it was activated. This means there is some feature, theme,\n",
    "methodology, topic or concept in this text that ‘excites’ this neuron.\n",
    "2. You will also be given several examples of text that don’t activate the neuron. This\n",
    "means the feature, topic or concept is not present in these texts.\n",
    "OUTPUT DESCRIPTION: Given the inputs provided, complete the following tasks.\n",
    "1. Based on the MAX ACTIVATING EXAMPLES provided, write down potential topics,\n",
    "concepts, themes, methodologies and features that they share in common. These\n",
    "will need to be specific - remember, all of the text comes from subject, so these\n",
    "need to be highly specific subject concepts. You may need to look at different\n",
    "levels of granularity (i.e. subsets of a more general topic). List as many as you can\n",
    "think of. Give higher weight to concepts more present/prominent in examples with\n",
    "higher activations.\n",
    "2. Based on the zero activating examples, rule out any of the topics/concepts/features\n",
    "listed above that are in the zero-activating examples. Systematically go through your\n",
    "list above.\n",
    "3. Based on the above two steps, perform a thorough analysis of which feature, concept\n",
    "or topic, at what level of granularity, is likely to activate this neuron. Use Occam’s\n",
    "razor, as long as it fits the provided evidence. Be highly rational and analytical here.\n",
    "4. Based on step 4, summarise this concept in 1-8 words, in the form FINAL:\n",
    "<explanation>. Do NOT return anything after these 1-8 words.\n",
    "Here are the max-activating examples:\n",
    "{max_examples}\n",
    "\n",
    "Here are the zero-activating examples:\n",
    "{zero_examples}\n",
    "\n",
    "Work through the steps thoroughly and analytically to interpret our neuron.\n",
    "Complete the following statement in less than 10 words: The neuron is likely responsible for:\"\"\""
   ],
   "id": "176b48b05aa31315",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T08:30:19.151211Z",
     "start_time": "2025-04-07T08:30:19.137886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(feature_id, subject=\"biomedical\", type=\"AI interpretability\"):\n",
    "    # Filtrar activaciones positivas que no sean cero\n",
    "    positive_activations = [act for act in top_activations[feature_id] if act[0] > 0]\n",
    "\n",
    "    if len(positive_activations) < NUM_POS:\n",
    "        print(f\"❗ Feature {feature_id} does not have enough positive examples.\")\n",
    "        return\n",
    "\n",
    "    positives = random.sample(positive_activations, k=NUM_POS)\n",
    "    negatives = negative_examples[feature_id]\n",
    "\n",
    "    if len(negatives) < NUM_NEG:\n",
    "        print(f\"❗ Feature {feature_id} does not have enough negative examples.\")\n",
    "        return\n",
    "\n",
    "    def format_examples(examples):\n",
    "        return \"\\n\\n\".join([f\"Activation: {act:.4f}\\n{text}\" for act, text in examples])\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        subject=subject,\n",
    "        type=type,\n",
    "        max_examples=format_examples(positives),\n",
    "        zero_examples=format_examples(negatives)\n",
    "    )\n",
    "\n",
    "    return prompt"
   ],
   "id": "79882d1de0cfd1ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### FIX THE JSON DUMP !!!",
   "id": "1b6bc475f2794669"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T09:46:58.530898Z",
     "start_time": "2025-04-07T09:46:54.634546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import json\n",
    "\n",
    "feature_descriptions = [None] * NUM_FEATURES\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"fireworks-ai\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "for feature_id in range(NUM_FEATURES):\n",
    "    prompt = create_prompt(feature_id, subject=\"biomedical\", type=\"AI interpretability\")\n",
    "    if prompt:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            if completion:\n",
    "                feature_descriptions[feature_id] = completion.choices[0].message[\"content\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing feature {feature_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if completion and feature_id % 100 == 0:\n",
    "            print(f\"{feature_id}/{NUM_FEATURES} completed. Saving results...\")\n",
    "            with open(\"feature_descriptions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(feature_descriptions, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "with open(\"feature_descriptions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    feature_descriptions = json.load(f)\n",
    "print(\"All features processed and saved.\")"
   ],
   "id": "5413545ab4f2522b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing feature 0: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0e-2cfe50ae1a8b12e3538bc17c;9045ac10-e213-4cc3-af68-45b5bf55685a)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 1: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-514261c41b8865b32dbb9599;70089c8c-3eb7-4645-aafa-9b59fc9e91c5)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 2: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-0f1daa351fd1f7a170bded7a;1205fd4d-b8f5-456d-8bd1-87dbc0c95ce1)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 3: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-662a00dc71f003b077133a32;ad7a5d94-87b1-47fa-b194-5b8d4cbad5c6)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 4: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-52e1a89e361af363395b0d6a;f109aec1-b12e-422f-a162-6d0a1c13b6f1)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 5: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-383e01413f5251fa22f0837b;4dc6ff31-cc78-45e2-8070-0b5cd1e08247)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 6: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f0f-54be0ad42213739e50d44148;81785c47-74a6-4728-b3ea-263ced4eda58)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "❗ Feature 7 does not have enough positive examples.\n",
      "Error processing feature 8: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-5e802c8e49aff76a5dca7a65;682a959f-233a-4402-91bf-edc24a79e608)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 9: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-61a94e0a16cdc8a2323ffd2d;049611ba-472f-48f1-a580-1713d3917f69)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "❗ Feature 10 does not have enough positive examples.\n",
      "Error processing feature 11: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-48b1fc9e31e5cb9f64c0d627;65a880d1-087d-499d-ac3a-7bf7cb464bae)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 12: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-49529d2a6ef536be1d0a71bf;7cea08fa-5c33-4877-85bf-20131369cac9)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 13: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-0984c4dc4647e5d064f206f5;2c58f150-97cf-4142-bc64-f38695b5eb48)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 14: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f10-62f1573378e6681c05f67d6f;29f5e0fb-f8d1-4de6-a1c4-a5b55c767710)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 15: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-1f7ef66967190a4b21251434;bc5f118a-eeab-4255-9942-06f0192c5fdd)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 16: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-57cdbdc838df9bc633f4fe9b;90e53a4f-f588-4dfd-8ade-616bb1ef364f)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 17: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-5f753fa036f8e57051df3e69;e5c92acf-5ce9-468b-8143-1900573fa44d)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 18: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-041a92881642112e37b4a9a8;14cd44c0-1429-4de9-b5d0-adbac05860d3)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "❗ Feature 19 does not have enough positive examples.\n",
      "Error processing feature 20: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-1534b8cf445772622f4f0c62;c4846803-508b-44d9-b792-3a60ec38f894)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "❗ Feature 21 does not have enough positive examples.\n",
      "Error processing feature 22: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f11-319b6ea3683333a55fc48963;fb5cbc41-f0eb-4203-b309-e47adb6d12ff)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n",
      "Error processing feature 23: 402 Client Error: Payment Required for url: https://router.huggingface.co/fireworks-ai/v1/chat/completions (Request ID: Root=1-67f39f12-71c2d1a207343b704241341f;1ac6479b-ed9d-4087-88d5-e08a7a7eb5df)\n",
      "\n",
      "Pay-as-you go is not enabled for provider fireworks-ai yet.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prompt:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 15\u001B[0m         completion \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmeta-llama/Llama-3.1-8B-Instruct\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m                \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m                \u001B[49m\u001B[43m}\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m completion:\n\u001B[0;32m     25\u001B[0m             feature_descriptions[feature_id] \u001B[38;5;241m=\u001B[39m completion\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\huggingface_hub\\inference\\_client.py:956\u001B[0m, in \u001B[0;36mInferenceClient.chat_completion\u001B[1;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001B[0m\n\u001B[0;32m    928\u001B[0m parameters \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    929\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload_model,\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_body \u001B[38;5;129;01mor\u001B[39;00m {}),\n\u001B[0;32m    948\u001B[0m }\n\u001B[0;32m    949\u001B[0m request_parameters \u001B[38;5;241m=\u001B[39m provider_helper\u001B[38;5;241m.\u001B[39mprepare_request(\n\u001B[0;32m    950\u001B[0m     inputs\u001B[38;5;241m=\u001B[39mmessages,\n\u001B[0;32m    951\u001B[0m     parameters\u001B[38;5;241m=\u001B[39mparameters,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    954\u001B[0m     api_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken,\n\u001B[0;32m    955\u001B[0m )\n\u001B[1;32m--> 956\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inner_post\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    959\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _stream_chat_completion_response(data)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\huggingface_hub\\inference\\_client.py:306\u001B[0m, in \u001B[0;36mInferenceClient._inner_post\u001B[1;34m(self, request_parameters, stream)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_as_binary(request_parameters\u001B[38;5;241m.\u001B[39mdata) \u001B[38;5;28;01mas\u001B[39;00m data_as_binary:\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 306\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mget_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrequest_parameters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m            \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_parameters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_as_binary\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_parameters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m    317\u001B[0m         \u001B[38;5;66;03m# Convert any `TimeoutError` to a `InferenceTimeoutError`\u001B[39;00m\n\u001B[0;32m    318\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InferenceTimeoutError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInference call timed out: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrequest_parameters\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merror\u001B[39;00m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\requests\\sessions.py:637\u001B[0m, in \u001B[0;36mSession.post\u001B[1;34m(self, url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    626\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\u001B[38;5;28mself\u001B[39m, url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    627\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[0;32m    628\u001B[0m \n\u001B[0;32m    629\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 637\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, json\u001B[38;5;241m=\u001B[39mjson, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001B[0m, in \u001B[0;36mUniqueRequestIdAdapter.send\u001B[1;34m(self, request, *args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSend: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_curlify(request)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m     request_id \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[0;32m    788\u001B[0m     conn,\n\u001B[0;32m    789\u001B[0m     method,\n\u001B[0;32m    790\u001B[0m     url,\n\u001B[0;32m    791\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[0;32m    792\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[0;32m    793\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m    794\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[0;32m    795\u001B[0m     retries\u001B[38;5;241m=\u001B[39mretries,\n\u001B[0;32m    796\u001B[0m     response_conn\u001B[38;5;241m=\u001B[39mresponse_conn,\n\u001B[0;32m    797\u001B[0m     preload_content\u001B[38;5;241m=\u001B[39mpreload_content,\n\u001B[0;32m    798\u001B[0m     decode_content\u001B[38;5;241m=\u001B[39mdecode_content,\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse_kw,\n\u001B[0;32m    800\u001B[0m )\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 534\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32mD:\\Escritorio\\PythonProyects\\SparseAutoencodersTFM\\.venv\\lib\\site-packages\\urllib3\\connection.py:516\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    513\u001B[0m _shutdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshutdown\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 516\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    519\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:1377\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1376\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1377\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:320\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\http\\client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1242\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1239\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1240\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1241\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1100\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1100\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
