This section provides an overview of the main results obtained from the project. Two models were trained: 

- JumpReLU SAE trained on [cs.LG](https://huggingface.co/datasets/UniverseTBD/arxiv-bit-flip-cs.LG) dataset. 
- JumpReLU SAE trained on [arxiv-astro-abstracts-all](https://huggingface.co/datasets/UniverseTBD/arxiv-astro-abstracts-all) dataset. 

The figure below shows the feature density histograms of both models. 

<p align="center">
  <img src="docs//assets/histograms.png" alt="Feature density histograms" width="600">
</p>




























--- 
For more details on the training results of the cs.LG SAE, see this [W&B run](https://huggingface.co/datasets/UniverseTBD/arxiv-astro-abstracts-all). 
For more details on the training results of the arxiv-astro-abstracts-all SAE, see this other [W&B run](https://wandb.ai/ybiku-unir/SBERT-SAEs-csLG/runs/a1pu5u76?nw=nwuserybiku).
